{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1SXYv8jR6oSNiSim8rbK61sQS1SBi4OIh",
      "authorship_tag": "ABX9TyNyy4uVAoJyyPJ1wsYT2UcS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/noahligala/Deep-Learning-/blob/GoogleColab/CropDiseaseDetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "mRGFIG9ySWAK"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from keras import models, layers\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_SIZE = 256\n",
        "BATCH_SIZE = 32\n",
        "CHANNELS = 3\n",
        "EPOCHS = 50"
      ],
      "metadata": {
        "id": "PgmPSqAXTdR1"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    \"./drive/MyDrive/Colab Notebooks/PlantVillage\",\n",
        "    shuffle=True,\n",
        "    image_size = (IMAGE_SIZE,IMAGE_SIZE),\n",
        "    batch_size = BATCH_SIZE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "we757TroThb7",
        "outputId": "f83ae10e-a12f-4527-f848-83c3f7c3df14"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 894 files belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = dataset.class_names\n",
        "class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2IYZw-vET6c8",
        "outputId": "e5f9639a-e17b-43ad-88d3-cca9b85b97ba"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Potato___Early_blight', 'Potato___Late_blight', 'Potato___healthy']"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Splitting**"
      ],
      "metadata": {
        "id": "RN-78OA5UDci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataset_partitions_tf(ds, train_split=0.8, val_split=0.1, shuffle=True, shuffle_size=10000):\n",
        "    \n",
        "    ds_size = len(ds)\n",
        "    \n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(shuffle_size, seed=12)\n",
        "        \n",
        "    train_size = int(train_split * ds_size)\n",
        "    val_size = int(val_split * ds_size)\n",
        "    \n",
        "    train_ds= ds.take(train_size)\n",
        "    \n",
        "    val_ds = ds.skip(train_size).take(val_size)\n",
        "    test_ds = ds.skip(train_size).skip(val_size)\n",
        "    \n",
        "    \n",
        "    return train_ds, val_ds, test_ds"
      ],
      "metadata": {
        "id": "AwX_cXvjUGDP"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds, val_ds, test_ds = get_dataset_partitions_tf(dataset)"
      ],
      "metadata": {
        "id": "9sUmEHUTUBmj"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Shuffling and Prefetch"
      ],
      "metadata": {
        "id": "fZVYHnQ1UbN-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "val_ds = val_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "test_ds = test_ds.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "FFY29eW3UX1A"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resize_and_rescale = tf.keras.Sequential([\n",
        "    layers.experimental.preprocessing.Resizing(IMAGE_SIZE, IMAGE_SIZE),\n",
        "    layers.experimental.preprocessing.Rescaling(1.0/255)\n",
        "])"
      ],
      "metadata": {
        "id": "zQhbsqLHUpVX"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_augmentation = tf.keras.Sequential ([\n",
        "    layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
        "    layers.experimental.preprocessing.RandomRotation(0.2)\n",
        "])"
      ],
      "metadata": {
        "id": "LtWS95KVUvVX"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Building the Model**"
      ],
      "metadata": {
        "id": "Rp9TdEcPU4Kb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, CHANNELS)\n",
        "n_classes = 3\n",
        "\n",
        "model = models.Sequential([\n",
        "    resize_and_rescale,\n",
        "    data_augmentation,\n",
        "    layers.Conv2D(32, (3,3), activation='relu', input_shape = input_shape),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, kernel_size = (3,3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(63, kernel_size = (3,3), activation='relu'),\n",
        "    #layers.MaxPooling2D((2, 2)),\n",
        "    layers.MaxPooling2D(pool_size=(2, 2),\n",
        "    strides=(1, 1), padding='valid'),\n",
        "    layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(n_classes, activation='softmax')\n",
        "])\n",
        "model.build(input_shape=input_shape)"
      ],
      "metadata": {
        "id": "17UZTYxjU0hj"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKUQbd2GU_Sf",
        "outputId": "a7cc56c4-53e3-4865-9d37-c3903a14b2aa"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " sequential (Sequential)     (32, 256, 256, 3)         0         \n",
            "                                                                 \n",
            " sequential_1 (Sequential)   (32, 256, 256, 3)         0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (32, 254, 254, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (32, 127, 127, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (32, 125, 125, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (32, 62, 62, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (32, 60, 60, 63)          36351     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (32, 59, 59, 63)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (32, 57, 57, 64)          36352     \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (32, 28, 28, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (32, 26, 26, 64)          36928     \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (32, 13, 13, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (32, 11, 11, 64)          36928     \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (32, 5, 5, 64)           0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (32, 1600)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (32, 64)                  102464    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (32, 3)                   195       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 268,610\n",
            "Trainable params: 268,610\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "IEaPTNInVEj3"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_ds,\n",
        "    epochs = EPOCHS,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    verbose=1,\n",
        "    validation_data=val_ds\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBpaf1idVJ26",
        "outputId": "89dd9d88-9e1e-497f-b4df-80922ea48e16"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1/1 [==============================] - 3s 3s/step - loss: 1.1045 - accuracy: 0.1250\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.7766 - accuracy: 1.0000\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 1s 753ms/step - loss: 0.2854 - accuracy: 1.0000\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 1s 770ms/step - loss: 0.0109 - accuracy: 1.0000\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 1s 764ms/step - loss: 1.9982e-05 - accuracy: 1.0000\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 1s 758ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 1s 761ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 1s 776ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 1s 777ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 1s 757ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 1s 779ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 1s 764ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 1s 783ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 1s 760ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 1s 770ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 1s 758ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 1s 783ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 1s 783ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 1s 759ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 1s 764ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 1s 784ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 1s 771ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 1s 751ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 1s 751ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 1s 767ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 1s 765ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 1s 768ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 1s 769ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 1s 770ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 1s 762ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 1s 768ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 1s 760ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 1s 763ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 1s 781ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores = model.evaluate(test_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdDBXa5pVTIK",
        "outputId": "a776a729-7aee-4abf-b085-286dd14b653e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 484ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9cKGVdTVW_v",
        "outputId": "bf9e3194-44e3-4a17-f47f-5de9d0978539"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0, 1.0]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "IFX2dJV_VcII",
        "outputId": "60709222-0451-4152-f8e1-98bf6a3546d8"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-c2fd09281f2d>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'val_accuracy'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "batch = str(BATCH_SIZE)\n",
        "epoch = str(EPOCHS)\n",
        "filename = datetime.now().strftime('%Y-%m-%d_%H-%M-%S') + '_batch-' + batch + '_' + '_epoch-' + epoch + '.png'\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(range(EPOCHS), acc, label='Training Accuracy')\n",
        "plt.plot(range(EPOCHS), val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(range(EPOCHS), loss, label='Training Loss')\n",
        "plt.plot(range(EPOCHS), val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.savefig(filename)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "x69U5KCRVdlS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "for images_batch, labels_batch in test_ds.take(1):\n",
        "    \n",
        "    first_image = images_batch[0].numpy().astype('uint8')\n",
        "    first_label = labels_batch[0].numpy()\n",
        "    \n",
        "    print(\"first_image to predict\")\n",
        "    plt.imshow(first_image)\n",
        "    print(\"actual label:\" ,class_names[first_label])\n",
        "    \n",
        "    batch_prediction = model.predict(images_batch)\n",
        "    print(\"predicted label:\" ,class_names[np.argmax(batch_prediction[12])])"
      ],
      "metadata": {
        "id": "0BHc7JuOViPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model, img):\n",
        "    img_array = tf.keras.preprocessing.image.img_to_array(images[i].numpy)\n",
        "    img_array"
      ],
      "metadata": {
        "id": "ncFOuOCSVkxM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}